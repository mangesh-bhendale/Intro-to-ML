{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas # https://pandas.pydata.org/\n",
    "\n",
    "from sklearn import model_selection # for model comparisons\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file ...\n",
      "Removing rows with missing data ...\n",
      "Reading list of problem variables X and y...\n",
      "Partitioning data into parts: formative (for development) and summative (for testing) ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's set up our standard example problem: \n",
    "# Can we predict 'callSign' using these three features:  'Depth', 'Temperature', 'Salinity' ?\n",
    "\n",
    "# Load the data\n",
    "print('Loading data from file ...')  \n",
    "dataset = pandas.read_csv('floats.csv')\n",
    "print('Removing rows with missing data ...')  \n",
    "dataset = dataset.dropna()\n",
    "print('Reading list of problem variables X and y...')\n",
    "X_name = [ 'Depth', 'Temperature', 'Salinity' ] \n",
    "y_name = 'callSign'\n",
    "X = dataset[X_name]   \n",
    "y = dataset[y_name]   \n",
    "\n",
    "# setting the seed allows for repeatability\n",
    "seed = 42 \n",
    "\n",
    "print('Partitioning data into parts: formative (for development) and summative (for testing) ...')\n",
    "test_size = 0.20   # means 20 percent\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.32494616\n",
      "Iteration 2, loss = 2.80268947\n",
      "Iteration 3, loss = 2.40650008\n",
      "Iteration 4, loss = 2.64771481\n",
      "Iteration 5, loss = 3.33118997\n",
      "Iteration 6, loss = 2.31756592\n",
      "Iteration 7, loss = 2.05321711\n",
      "Iteration 8, loss = 2.31372871\n",
      "Iteration 9, loss = 2.62359178\n",
      "Iteration 10, loss = 2.26290398\n",
      "Iteration 11, loss = 2.41188133\n",
      "Iteration 12, loss = 2.04787509\n",
      "Iteration 13, loss = 2.47939312\n",
      "Iteration 14, loss = 1.91802623\n",
      "Iteration 15, loss = 1.88256853\n",
      "Iteration 16, loss = 1.93213124\n",
      "Iteration 17, loss = 2.04123177\n",
      "Iteration 18, loss = 2.05288884\n",
      "Iteration 19, loss = 1.95980187\n",
      "Iteration 20, loss = 1.84456772\n",
      "Iteration 21, loss = 2.01341282\n",
      "Iteration 22, loss = 2.07397885\n",
      "Iteration 23, loss = 1.95806103\n",
      "Iteration 24, loss = 2.01404005\n",
      "Iteration 25, loss = 1.91152440\n",
      "Iteration 26, loss = 1.92427125\n",
      "Iteration 27, loss = 1.87890831\n",
      "Iteration 28, loss = 1.85667178\n",
      "Iteration 29, loss = 1.83265928\n",
      "Iteration 30, loss = 1.81837360\n",
      "Iteration 31, loss = 1.82375676\n",
      "Iteration 32, loss = 1.78871468\n",
      "Iteration 33, loss = 1.90327170\n",
      "Iteration 34, loss = 1.80231816\n",
      "Iteration 35, loss = 1.77085754\n",
      "Iteration 36, loss = 1.86769954\n",
      "Iteration 37, loss = 1.95005416\n",
      "Iteration 38, loss = 1.79517247\n",
      "Iteration 39, loss = 1.78012468\n",
      "Iteration 40, loss = 1.74655713\n",
      "Iteration 41, loss = 1.74662884\n",
      "Iteration 42, loss = 1.74923691\n",
      "Iteration 43, loss = 1.84432875\n",
      "Iteration 44, loss = 1.78260781\n",
      "Iteration 45, loss = 1.73478454\n",
      "Iteration 46, loss = 1.75665539\n",
      "Iteration 47, loss = 1.80386303\n",
      "Iteration 48, loss = 1.73978565\n",
      "Iteration 49, loss = 1.75052348\n",
      "Iteration 50, loss = 1.75208410\n",
      "Iteration 51, loss = 1.73866690\n",
      "Iteration 52, loss = 1.71014795\n",
      "Iteration 53, loss = 1.73658062\n",
      "Iteration 54, loss = 1.79974166\n",
      "Iteration 55, loss = 1.70641572\n",
      "Iteration 56, loss = 1.78348769\n",
      "Iteration 57, loss = 1.74138215\n",
      "Iteration 58, loss = 1.74746049\n",
      "Iteration 59, loss = 1.72496924\n",
      "Iteration 60, loss = 1.71728189\n",
      "Iteration 61, loss = 1.84340929\n",
      "Iteration 62, loss = 1.71193617\n",
      "Iteration 63, loss = 1.71238920\n",
      "Iteration 64, loss = 1.71236549\n",
      "Iteration 65, loss = 1.75481165\n",
      "Iteration 66, loss = 1.69544797\n",
      "Iteration 67, loss = 1.68559371\n",
      "Iteration 68, loss = 1.69441713\n",
      "Iteration 69, loss = 1.71114300\n",
      "Iteration 70, loss = 1.79370594\n",
      "Iteration 71, loss = 1.73088531\n",
      "Iteration 72, loss = 1.68654021\n",
      "Iteration 73, loss = 1.68685943\n",
      "Iteration 74, loss = 1.67570295\n",
      "Iteration 75, loss = 1.68947083\n",
      "Iteration 76, loss = 1.68812644\n",
      "Iteration 77, loss = 1.64728147\n",
      "Iteration 78, loss = 1.67730909\n",
      "Iteration 79, loss = 1.67545263\n",
      "Iteration 80, loss = 1.66466734\n",
      "Iteration 81, loss = 1.65904422\n",
      "Iteration 82, loss = 1.65983233\n",
      "Iteration 83, loss = 1.65340441\n",
      "Iteration 84, loss = 1.70405148\n",
      "Iteration 85, loss = 1.73108460\n",
      "Iteration 86, loss = 1.64083499\n",
      "Iteration 87, loss = 1.65201816\n",
      "Iteration 88, loss = 1.68272302\n",
      "Iteration 89, loss = 1.65222731\n",
      "Iteration 90, loss = 1.74199201\n",
      "Iteration 91, loss = 1.76789341\n",
      "Iteration 92, loss = 1.67652416\n",
      "Iteration 93, loss = 1.69106983\n",
      "Iteration 94, loss = 1.65658560\n",
      "Iteration 95, loss = 1.64005110\n",
      "Iteration 96, loss = 1.65279876\n",
      "Iteration 97, loss = 1.64655022\n",
      "Iteration 98, loss = 1.63858929\n",
      "Iteration 99, loss = 1.63845749\n",
      "Iteration 100, loss = 1.66642262\n",
      "Training set score: 0.405689\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Design the classifier neural network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), # two hidden layers; first has 10 LUs, next has 50 LUs\n",
    "                    activation = 'relu',  # ReLU is the default option\n",
    "                    # solver='sgd',  # default is Adam\n",
    "                    alpha=0.01,  # regularization parameter, default is 0.0001 (increase up to 1.0 for stronger regularization)\n",
    "                    learning_rate_init=.01 ,  # initial step-size for updating the weights, default is 0.001\n",
    "                    max_iter=100,  # number of epochs, default=200\n",
    "                    random_state=seed,\n",
    "                    verbose=1, \n",
    "                    )\n",
    "\n",
    "# Train the classifier\n",
    " \n",
    "# in case the training won't converge we catch the warning and ignore it\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Q4901043       0.52      0.65      0.57       179\n",
      "    Q4901044       0.58      0.86      0.69       573\n",
      "    Q4901265       0.20      0.58      0.30       172\n",
      "    Q4901266       0.14      0.12      0.13       195\n",
      "    Q4901267       0.31      0.45      0.37       167\n",
      "    Q4901268       0.00      0.00      0.00       132\n",
      "    Q4901269       0.22      0.01      0.02       191\n",
      "    Q4901270       0.43      0.02      0.03       190\n",
      "    Q4901271       0.00      0.00      0.00        92\n",
      "    Q4901272       0.00      0.00      0.00       103\n",
      "    Q4901273       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.40      2005\n",
      "   macro avg       0.22      0.24      0.19      2005\n",
      "weighted avg       0.33      0.40      0.32      2005\n",
      "\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/dsi/apps/anaconda3/python-3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_predicted = mlp.predict(X_test)   # use the trained classifier to predict on the test set\n",
    "\n",
    "print('\\n clasification report:\\n', classification_report(y_test, y_predicted))  # compare predictions with ground truth\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
